# Existing Word Embedding Techniques are - 
1. BERT
2. FinBert
3. RoBerta
4. DistillBert

# LDA & LSA
Matrix based models.
Topics are produced based on word frequency.
Fail to work on large corpus as they have sparsity issue.
Ignores the order of words, hence semantic relationship between the words is not captured.


# Embedded Space Models
Vector based models.
Topics are extracted by grouping the similar meaning words together
Works effectively on large corpus.
Considers the order of words and captures the semantic relationship between the words.
