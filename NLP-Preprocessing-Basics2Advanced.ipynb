{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f73640c",
   "metadata": {},
   "source": [
    "# NLP Basics\n",
    "1. Lowercasing\n",
    "2. Remove HTML Tags\n",
    "3. Remove URLs\n",
    "4. Remove Punctuations\n",
    "5. Chat word treatment\n",
    "6. Spelling Correction\n",
    "7. Removing Stop Words\n",
    "8. Handling Emojis\n",
    "9. Tokenization\n",
    "10. Stemming\n",
    "11. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c008d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8948673",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_colwidth\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ba3361b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.&lt;br /&gt;&lt;br /&gt;The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.&lt;br /&gt;&lt;br /&gt;It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.&lt;br /&gt;&lt;br /&gt;I would say the main appeal of the show is due to the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. &lt;br /&gt;&lt;br /&gt;The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. &lt;br /&gt;&lt;br /&gt;The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    review  \\\n",
       "0  One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the...   \n",
       "1   A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.   \n",
       "\n",
       "  sentiment  \n",
       "0  positive  \n",
       "1  positive  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/IMDB Dataset.csv\")\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9586ac0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f865d37",
   "metadata": {},
   "source": [
    "## Lower Casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c76dc614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert complete review column into lower case.\n",
    "data[\"review\"] = data[\"review\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cdaa3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that after watching just 1 oz episode you'll be hooked. they are right, as this is exactly what happened with me.&lt;br /&gt;&lt;br /&gt;the first thing that struck me about oz was its brutality and unflinching scenes of violence, which set in right from the word go. trust me, this is not a show for the faint hearted or timid. this show pulls no punches with regards to drugs, sex or violence. its is hardcore, in the classic use of the word.&lt;br /&gt;&lt;br /&gt;it is called oz as that is the nickname given to the oswald maximum security state penitentary. it focuses mainly on emerald city, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. em city is home to many..aryans, muslims, gangstas, latinos, christians, italians, irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.&lt;br /&gt;&lt;br /&gt;i would say the main appeal of the show is due to the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the filming technique is very unassuming- very old-time-bbc fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. &lt;br /&gt;&lt;br /&gt;the actors are extremely well chosen- michael sheen not only \"has got all the polari\" but he has all the voices down pat too! you can truly see the seamless editing guided by the references to williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. a masterful production about one of the great master's of comedy and his life. &lt;br /&gt;&lt;br /&gt;the realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. it plays on our knowledge and our senses, particularly with the scenes concerning orton and halliwell and the sets (particularly of their flat with halliwell's murals decorating every surface) are terribly well done.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    review  \\\n",
       "0  one of the other reviewers has mentioned that after watching just 1 oz episode you'll be hooked. they are right, as this is exactly what happened with me.<br /><br />the first thing that struck me about oz was its brutality and unflinching scenes of violence, which set in right from the word go. trust me, this is not a show for the faint hearted or timid. this show pulls no punches with regards to drugs, sex or violence. its is hardcore, in the classic use of the word.<br /><br />it is called oz as that is the nickname given to the oswald maximum security state penitentary. it focuses mainly on emerald city, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. em city is home to many..aryans, muslims, gangstas, latinos, christians, italians, irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />i would say the main appeal of the show is due to the...   \n",
       "1   a wonderful little production. <br /><br />the filming technique is very unassuming- very old-time-bbc fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />the actors are extremely well chosen- michael sheen not only \"has got all the polari\" but he has all the voices down pat too! you can truly see the seamless editing guided by the references to williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. a masterful production about one of the great master's of comedy and his life. <br /><br />the realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. it plays on our knowledge and our senses, particularly with the scenes concerning orton and halliwell and the sets (particularly of their flat with halliwell's murals decorating every surface) are terribly well done.   \n",
       "\n",
       "  sentiment  \n",
       "0  positive  \n",
       "1  positive  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f4828f",
   "metadata": {},
   "source": [
    "# Removing HTML Tags\n",
    "\n",
    "https://regex101.com/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f243ba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_html_tags(text):\n",
    "    pattern = re.compile(\"<.*?>\")\n",
    "    return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90208449",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"<div class=\"ipc-html-content-inner-div\">Earth's future has been riddled by disasters, famines, and droughts. There is only one way to ensure mankind's survival: Interstellar travel. A newly discovered wormhole in the far reaches of our solar system allows a team of astronauts to go where no man has gone before, a planet that may have the right environment to sustain human life.<span style=\"display:inline-block\" data-reactroot=\"\"> <!-- -->—<a class=\"ipc-link ipc-link--base sc-9eebdf80-0 VsoxL\" role=\"button\" tabindex=\"0\" aria-disabled=\"false\" href=\"/search/title/?plot_author=ahmetkozan&amp;view=simple&amp;sort=alpha&amp;ref_=tt_stry_pl\">ahmetkozan</a></span></div>away.br />br />i \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3afdcd43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Earth's future has been riddled by disasters, famines, and droughts. There is only one way to ensure mankind's survival: Interstellar travel. A newly discovered wormhole in the far reaches of our solar system allows a team of astronauts to go where no man has gone before, a planet that may have the right environment to sustain human life. —ahmetkozanaway.br />br />i \\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "remove_html_tags(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab977286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing tags from the review column\n",
    "data[\"review\"] = data[\"review\"].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7033c368",
   "metadata": {},
   "source": [
    "# Removing URLs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba3d0732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ea9f292",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \" this is the urls of intersteller movie imdb https://www.imdb.com/title/tt0816692/?ref_=ttls_li_tt very good movie to watch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2db56ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' this is the urls of intersteller movie imdb  very good movie to watch'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d941f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing URLs from the review column\n",
    "data[\"review\"] = data[\"review\"].apply(remove_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb67c8d",
   "metadata": {},
   "source": [
    "# Removing Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e179a3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string, time\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b91e80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f09f140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good but time consuming function\n",
    "def remove_punc(text):\n",
    "    for char in exclude:\n",
    "        text = text.replace(char,\"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51d865d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"What's your full name? Y'day was a holiday.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e036fbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whats your full name Yday was a holiday\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(remove_punc(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "812e9800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whats your full name Yday was a holiday\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(remove_punc(text))\n",
    "time1 = time.time() - start\n",
    "print(time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b579a3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    return text.translate(str.maketrans(\"\",\"\",exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dde9f7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whats your full name Yday was a holiday\n"
     ]
    }
   ],
   "source": [
    "print(remove_punc(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b52aa569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whats your full name Yday was a holiday\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(remove_punc(text))\n",
    "time1 = time.time() - start\n",
    "print(time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27b217b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuations from the review column\n",
    "data[\"review\"] = data[\"review\"].apply(remove_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59729709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that after watching just 1 oz episode youll be hooked they are right as this is exactly what happened with methe first thing that struck me about oz was its brutality and unflinching scenes of violence which set in right from the word go trust me this is not a show for the faint hearted or timid this show pulls no punches with regards to drugs sex or violence its is hardcore in the classic use of the wordit is called oz as that is the nickname given to the oswald maximum security state penitentary it focuses mainly on emerald city an experimental section of the prison where all the cells have glass fronts and face inwards so privacy is not high on the agenda em city is home to manyaryans muslims gangstas latinos christians italians irish and moreso scuffles death stares dodgy dealings and shady agreements are never far awayi would say the main appeal of the show is due to the fact that it goes where other shows wouldnt dare forget pretty pic...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production the filming technique is very unassuming very oldtimebbc fashion and gives a comforting and sometimes discomforting sense of realism to the entire piece the actors are extremely well chosen michael sheen not only has got all the polari but he has all the voices down pat too you can truly see the seamless editing guided by the references to williams diary entries not only is it well worth the watching but it is a terrificly written and performed piece a masterful production about one of the great masters of comedy and his life the realism really comes home with the little things the fantasy of the guard which rather than use the traditional dream techniques remains solid then disappears it plays on our knowledge and our senses particularly with the scenes concerning orton and halliwell and the sets particularly of their flat with halliwells murals decorating every surface are terribly well done</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    review  \\\n",
       "0  one of the other reviewers has mentioned that after watching just 1 oz episode youll be hooked they are right as this is exactly what happened with methe first thing that struck me about oz was its brutality and unflinching scenes of violence which set in right from the word go trust me this is not a show for the faint hearted or timid this show pulls no punches with regards to drugs sex or violence its is hardcore in the classic use of the wordit is called oz as that is the nickname given to the oswald maximum security state penitentary it focuses mainly on emerald city an experimental section of the prison where all the cells have glass fronts and face inwards so privacy is not high on the agenda em city is home to manyaryans muslims gangstas latinos christians italians irish and moreso scuffles death stares dodgy dealings and shady agreements are never far awayi would say the main appeal of the show is due to the fact that it goes where other shows wouldnt dare forget pretty pic...   \n",
       "1                                                                 a wonderful little production the filming technique is very unassuming very oldtimebbc fashion and gives a comforting and sometimes discomforting sense of realism to the entire piece the actors are extremely well chosen michael sheen not only has got all the polari but he has all the voices down pat too you can truly see the seamless editing guided by the references to williams diary entries not only is it well worth the watching but it is a terrificly written and performed piece a masterful production about one of the great masters of comedy and his life the realism really comes home with the little things the fantasy of the guard which rather than use the traditional dream techniques remains solid then disappears it plays on our knowledge and our senses particularly with the scenes concerning orton and halliwell and the sets particularly of their flat with halliwells murals decorating every surface are terribly well done   \n",
       "\n",
       "  sentiment  \n",
       "0  positive  \n",
       "1  positive  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dfc8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8afa5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"./data/slang.txt\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee75af2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.seek(0)\n",
    "chat_words_str = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e818f022",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file.seek(0)\n",
    "#chat_words_str = ''.join(map(str, file.readlines())).splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53350139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AFAIK=As Far As I Know',\n",
       " 'AFK=Away From Keyboard',\n",
       " 'ASAP=As Soon As Possible',\n",
       " 'ATK=At The Keyboard',\n",
       " 'ATM=At The Moment',\n",
       " 'A3=Anytime, Anywhere, Anyplace',\n",
       " 'BAK=Back At Keyboard',\n",
       " 'BBL=Be Back Later',\n",
       " 'BBS=Be Back Soon',\n",
       " 'BFN=Bye For Now',\n",
       " 'B4N=Bye For Now',\n",
       " 'BRB=Be Right Back',\n",
       " 'BRT=Be Right There',\n",
       " 'BTW=By The Way',\n",
       " 'B4=Before',\n",
       " 'B4N=Bye For Now',\n",
       " 'CU=See You',\n",
       " 'CUL8R=See You Later',\n",
       " 'CYA=See You',\n",
       " 'FAQ=Frequently Asked Questions',\n",
       " 'FC=Fingers Crossed',\n",
       " \"FWIW=For What It's Worth\",\n",
       " 'FYI=For Your Information',\n",
       " 'GAL=Get A Life',\n",
       " 'GG=Good Game',\n",
       " 'GN=Good Night',\n",
       " 'GMTA=Great Minds Think Alike',\n",
       " 'GR8=Great!',\n",
       " 'G9=Genius',\n",
       " 'IC=I See',\n",
       " 'ICQ=I Seek you (also a chat program)',\n",
       " 'ILU=ILU: I Love You',\n",
       " 'IMHO=In My Honest/Humble Opinion',\n",
       " 'IMO=In My Opinion',\n",
       " 'IOW=In Other Words',\n",
       " 'IRL=In Real Life',\n",
       " 'KISS=Keep It Simple, Stupid',\n",
       " 'LDR=Long Distance Relationship',\n",
       " 'LMAO=Laugh My A.. Off',\n",
       " 'LOL=Laughing Out Loud',\n",
       " 'LTNS=Long Time No See',\n",
       " 'L8R=Later',\n",
       " 'MTE=My Thoughts Exactly',\n",
       " 'M8=Mate',\n",
       " 'NRN=No Reply Necessary',\n",
       " 'OIC=Oh I See',\n",
       " 'PITA=Pain In The A..',\n",
       " 'PRT=Party',\n",
       " 'PRW=Parents Are Watching',\n",
       " 'ROFL=Rolling On The Floor Laughing',\n",
       " 'ROFLOL=Rolling On The Floor Laughing Out Loud',\n",
       " 'ROTFLMAO=Rolling On The Floor Laughing My A.. Off',\n",
       " 'SK8=Skate',\n",
       " 'STATS=Your sex and age',\n",
       " 'ASL=Age, Sex, Location',\n",
       " 'THX=Thank You',\n",
       " 'TTFN=Ta-Ta For Now!',\n",
       " 'TTYL=Talk To You Later',\n",
       " 'U=You',\n",
       " 'U2=You Too',\n",
       " 'U4E=Yours For Ever',\n",
       " 'WB=Welcome Back',\n",
       " 'WTF=What The F...',\n",
       " 'WTG=Way To Go!',\n",
       " 'WUF=Where Are You From?',\n",
       " 'W8=Wait...',\n",
       " '7K=Sick:-D Laugher']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_words_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fecc221b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFAIK=As Far As I Know\n",
      "AFK=Away From Keyboard\n",
      "ASAP=As Soon As Possible\n",
      "ATK=At The Keyboard\n",
      "ATM=At The Moment\n",
      "A3=Anytime, Anywhere, Anyplace\n",
      "BAK=Back At Keyboard\n",
      "BBL=Be Back Later\n",
      "BBS=Be Back Soon\n",
      "BFN=Bye For Now\n",
      "B4N=Bye For Now\n",
      "BRB=Be Right Back\n",
      "BRT=Be Right There\n",
      "BTW=By The Way\n",
      "B4=Before\n",
      "B4N=Bye For Now\n",
      "CU=See You\n",
      "CUL8R=See You Later\n",
      "CYA=See You\n",
      "FAQ=Frequently Asked Questions\n",
      "FC=Fingers Crossed\n",
      "FWIW=For What It's Worth\n",
      "FYI=For Your Information\n",
      "GAL=Get A Life\n",
      "GG=Good Game\n",
      "GN=Good Night\n",
      "GMTA=Great Minds Think Alike\n",
      "GR8=Great!\n",
      "G9=Genius\n",
      "IC=I See\n",
      "ICQ=I Seek you (also a chat program)\n",
      "ILU=ILU: I Love You\n",
      "IMHO=In My Honest/Humble Opinion\n",
      "IMO=In My Opinion\n",
      "IOW=In Other Words\n",
      "IRL=In Real Life\n",
      "KISS=Keep It Simple, Stupid\n",
      "LDR=Long Distance Relationship\n",
      "LMAO=Laugh My A.. Off\n",
      "LOL=Laughing Out Loud\n",
      "LTNS=Long Time No See\n",
      "L8R=Later\n",
      "MTE=My Thoughts Exactly\n",
      "M8=Mate\n",
      "NRN=No Reply Necessary\n",
      "OIC=Oh I See\n",
      "PITA=Pain In The A..\n",
      "PRT=Party\n",
      "PRW=Parents Are Watching\n",
      "ROFL=Rolling On The Floor Laughing\n",
      "ROFLOL=Rolling On The Floor Laughing Out Loud\n",
      "ROTFLMAO=Rolling On The Floor Laughing My A.. Off\n",
      "SK8=Skate\n",
      "STATS=Your sex and age\n",
      "ASL=Age, Sex, Location\n",
      "THX=Thank You\n",
      "TTFN=Ta-Ta For Now!\n",
      "TTYL=Talk To You Later\n",
      "U=You\n",
      "U2=You Too\n",
      "U4E=Yours For Ever\n",
      "WB=Welcome Back\n",
      "WTF=What The F...\n",
      "WTG=Way To Go!\n",
      "WUF=Where Are You From?\n",
      "W8=Wait...\n",
      "7K=Sick:-D Laugher\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mystr = \"\"\n",
    "for i in chat_words_str:\n",
    "    mystr = mystr + i+\"\\n\"\n",
    "    \n",
    "print(mystr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a924ffcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_words_str = \"\"\"\n",
    "AFAIK=As Far As I Know\n",
    "AFK=Away From Keyboard\n",
    "ASAP=As Soon As Possible\n",
    "ATK=At The Keyboard\n",
    "ATM=At The Moment\n",
    "A3=Anytime, Anywhere, Anyplace\n",
    "BAK=Back At Keyboard\n",
    "BBL=Be Back Later\n",
    "BBS=Be Back Soon\n",
    "BFN=Bye For Now\n",
    "B4N=Bye For Now\n",
    "BRB=Be Right Back\n",
    "BRT=Be Right There\n",
    "BTW=By The Way\n",
    "B4=Before\n",
    "B4N=Bye For Now\n",
    "CU=See You\n",
    "CUL8R=See You Later\n",
    "CYA=See You\n",
    "FAQ=Frequently Asked Questions\n",
    "FC=Fingers Crossed\n",
    "FWIW=For What It's Worth\n",
    "FYI=For Your Information\n",
    "GAL=Get A Life\n",
    "GG=Good Game\n",
    "GN=Good Night\n",
    "GMTA=Great Minds Think Alike\n",
    "GR8=Great!\n",
    "G9=Genius\n",
    "IC=I See\n",
    "ICQ=I Seek you (also a chat program)\n",
    "ILU=ILU: I Love You\n",
    "IMHO=In My Honest/Humble Opinion\n",
    "IMO=In My Opinion\n",
    "IOW=In Other Words\n",
    "IRL=In Real Life\n",
    "KISS=Keep It Simple, Stupid\n",
    "LDR=Long Distance Relationship\n",
    "LMAO=Laugh My A.. Off\n",
    "LOL=Laughing Out Loud\n",
    "LTNS=Long Time No See\n",
    "L8R=Later\n",
    "MTE=My Thoughts Exactly\n",
    "M8=Mate\n",
    "NRN=No Reply Necessary\n",
    "OIC=Oh I See\n",
    "PITA=Pain In The A..\n",
    "PRT=Party\n",
    "PRW=Parents Are Watching\n",
    "ROFL=Rolling On The Floor Laughing\n",
    "ROFLOL=Rolling On The Floor Laughing Out Loud\n",
    "ROTFLMAO=Rolling On The Floor Laughing My A.. Off\n",
    "SK8=Skate\n",
    "STATS=Your sex and age\n",
    "ASL=Age, Sex, Location\n",
    "THX=Thank You\n",
    "TTFN=Ta-Ta For Now!\n",
    "TTYL=Talk To You Later\n",
    "U=You\n",
    "U2=You Too\n",
    "U4E=Yours For Ever\n",
    "WB=Welcome Back\n",
    "WTF=What The F...\n",
    "WTG=Way To Go!\n",
    "WUF=Where Are You From?\n",
    "W8=Wait...\n",
    "7K=Sick:-D Laugher\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "607ee2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_words_list = []\n",
    "chat_words_map_dict = {}\n",
    "for line in chat_words_str.split(\"\\n\"):\n",
    "    if line != \"\":\n",
    "        cw = line.split(\"=\")[0]\n",
    "        cw_expanded = line.split(\"=\")[1]\n",
    "        chat_words_list.append(cw)\n",
    "        chat_words_map_dict[cw] = cw_expanded\n",
    "chat_words_list = set(chat_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92e196f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_words_conversion(text):\n",
    "    new_text = []\n",
    "    for w in text.split():\n",
    "        if w.upper() in chat_words_list:\n",
    "            new_text.append(chat_words_map_dict[w.upper()])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dcb6d890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In My Opinion this is awesome'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_words_conversion(\"imo this is awesome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "934bea10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In My Honest/Humble Opinion he is the best'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_words_conversion('IMHO he is the best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b954b23",
   "metadata": {},
   "source": [
    "# Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f73f6de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42f4038d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'there you go. I hope it correct the spelling right'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_text = 'theree you goo. I hoope it corrrect hte spellling rigtl'\n",
    "\n",
    "textBlb = TextBlob(incorrect_text)\n",
    "\n",
    "textBlb.correct().string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac09f4e2",
   "metadata": {},
   "source": [
    "# Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2686b7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dec62b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arabic', 'azerbaijani', 'basque', 'bengali', 'catalan', 'chinese', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'greek', 'hebrew', 'hinglish', 'hungarian', 'indonesian', 'italian', 'kazakh', 'nepali', 'norwegian', 'portuguese', 'romanian', 'russian', 'slovene', 'spanish', 'swedish', 'tajik', 'turkish']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "98acf446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd0ae09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61169460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'aadi',\n",
       " 'aaj',\n",
       " 'aap',\n",
       " 'aapne',\n",
       " 'aata',\n",
       " 'aati',\n",
       " 'aaya',\n",
       " 'aaye',\n",
       " 'ab',\n",
       " 'abbe',\n",
       " 'abbey',\n",
       " 'abe',\n",
       " 'abhi',\n",
       " 'able',\n",
       " 'about',\n",
       " 'above',\n",
       " 'accha',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'acha',\n",
       " 'achcha',\n",
       " 'across',\n",
       " 'actually',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'agar',\n",
       " 'ain',\n",
       " 'aint',\n",
       " \"ain't\",\n",
       " 'aisa',\n",
       " 'aise',\n",
       " 'aisi',\n",
       " 'alag',\n",
       " 'all',\n",
       " 'allow',\n",
       " 'allows',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'an',\n",
       " 'and',\n",
       " 'andar',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anyhow',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'ap',\n",
       " 'apan',\n",
       " 'apart',\n",
       " 'apna',\n",
       " 'apnaa',\n",
       " 'apne',\n",
       " 'apni',\n",
       " 'appear',\n",
       " 'are',\n",
       " 'aren',\n",
       " 'arent',\n",
       " \"aren't\",\n",
       " 'around',\n",
       " 'arre',\n",
       " 'as',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asking',\n",
       " 'at',\n",
       " 'aur',\n",
       " 'avum',\n",
       " 'aya',\n",
       " 'aye',\n",
       " 'baad',\n",
       " 'baar',\n",
       " 'bad',\n",
       " 'bahut',\n",
       " 'bana',\n",
       " 'banae',\n",
       " 'banai',\n",
       " 'banao',\n",
       " 'banaya',\n",
       " 'banaye',\n",
       " 'banayi',\n",
       " 'banda',\n",
       " 'bande',\n",
       " 'bandi',\n",
       " 'bane',\n",
       " 'bani',\n",
       " 'bas',\n",
       " 'bata',\n",
       " 'batao',\n",
       " 'bc',\n",
       " 'be',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'better',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'bhai',\n",
       " 'bheetar',\n",
       " 'bhi',\n",
       " 'bhitar',\n",
       " 'bht',\n",
       " 'bilkul',\n",
       " 'bohot',\n",
       " 'bol',\n",
       " 'bola',\n",
       " 'bole',\n",
       " 'boli',\n",
       " 'bolo',\n",
       " 'bolta',\n",
       " 'bolte',\n",
       " 'bolti',\n",
       " 'both',\n",
       " 'brief',\n",
       " 'bro',\n",
       " 'btw',\n",
       " 'but',\n",
       " 'by',\n",
       " 'came',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'cant',\n",
       " \"can't\",\n",
       " 'cause',\n",
       " 'causes',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'chahiye',\n",
       " 'chaiye',\n",
       " 'chal',\n",
       " 'chalega',\n",
       " 'chhaiye',\n",
       " 'clearly',\n",
       " \"c'mon\",\n",
       " 'com',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'could',\n",
       " 'couldn',\n",
       " 'couldnt',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'de',\n",
       " 'dede',\n",
       " 'dega',\n",
       " 'degi',\n",
       " 'dekh',\n",
       " 'dekha',\n",
       " 'dekhe',\n",
       " 'dekhi',\n",
       " 'dekho',\n",
       " 'denge',\n",
       " 'dhang',\n",
       " 'di',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'didnt',\n",
       " \"didn't\",\n",
       " 'dijiye',\n",
       " 'diya',\n",
       " 'diyaa',\n",
       " 'diye',\n",
       " 'diyo',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'doesnt',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'done',\n",
       " 'dono',\n",
       " 'dont',\n",
       " \"don't\",\n",
       " 'doosra',\n",
       " 'doosre',\n",
       " 'down',\n",
       " 'downwards',\n",
       " 'dude',\n",
       " 'dunga',\n",
       " 'dungi',\n",
       " 'during',\n",
       " 'dusra',\n",
       " 'dusre',\n",
       " 'dusri',\n",
       " 'dvaara',\n",
       " 'dvara',\n",
       " 'dwaara',\n",
       " 'dwara',\n",
       " 'each',\n",
       " 'edu',\n",
       " 'eg',\n",
       " 'eight',\n",
       " 'either',\n",
       " 'ek',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'enough',\n",
       " 'etc',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everybody',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'ex',\n",
       " 'exactly',\n",
       " 'example',\n",
       " 'except',\n",
       " 'far',\n",
       " 'few',\n",
       " 'fifth',\n",
       " 'fir',\n",
       " 'first',\n",
       " 'five',\n",
       " 'followed',\n",
       " 'following',\n",
       " 'follows',\n",
       " 'for',\n",
       " 'forth',\n",
       " 'four',\n",
       " 'from',\n",
       " 'further',\n",
       " 'furthermore',\n",
       " 'gaya',\n",
       " 'gaye',\n",
       " 'gayi',\n",
       " 'get',\n",
       " 'gets',\n",
       " 'getting',\n",
       " 'ghar',\n",
       " 'given',\n",
       " 'gives',\n",
       " 'go',\n",
       " 'goes',\n",
       " 'going',\n",
       " 'gone',\n",
       " 'good',\n",
       " 'got',\n",
       " 'gotten',\n",
       " 'greetings',\n",
       " 'haan',\n",
       " 'had',\n",
       " 'hadd',\n",
       " 'hadn',\n",
       " 'hadnt',\n",
       " \"hadn't\",\n",
       " 'hai',\n",
       " 'hain',\n",
       " 'hamara',\n",
       " 'hamare',\n",
       " 'hamari',\n",
       " 'hamne',\n",
       " 'han',\n",
       " 'happens',\n",
       " 'har',\n",
       " 'hardly',\n",
       " 'has',\n",
       " 'hasn',\n",
       " 'hasnt',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " 'havent',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'hello',\n",
       " 'help',\n",
       " 'hence',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " \"here's\",\n",
       " 'hereupon',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'hi',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'hither',\n",
       " 'hm',\n",
       " 'hmm',\n",
       " 'ho',\n",
       " 'hoga',\n",
       " 'hoge',\n",
       " 'hogi',\n",
       " 'hona',\n",
       " 'honaa',\n",
       " 'hone',\n",
       " 'honge',\n",
       " 'hongi',\n",
       " 'honi',\n",
       " 'hopefully',\n",
       " 'hota',\n",
       " 'hotaa',\n",
       " 'hote',\n",
       " 'hoti',\n",
       " 'how',\n",
       " 'howbeit',\n",
       " 'however',\n",
       " 'hoyenge',\n",
       " 'hoyengi',\n",
       " 'hu',\n",
       " 'hua',\n",
       " 'hue',\n",
       " 'huh',\n",
       " 'hui',\n",
       " 'hum',\n",
       " 'humein',\n",
       " 'humne',\n",
       " 'hun',\n",
       " 'huye',\n",
       " 'huyi',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'idk',\n",
       " 'ie',\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'imo',\n",
       " 'in',\n",
       " 'inasmuch',\n",
       " 'inc',\n",
       " 'inhe',\n",
       " 'inhi',\n",
       " 'inho',\n",
       " 'inka',\n",
       " 'inkaa',\n",
       " 'inke',\n",
       " 'inki',\n",
       " 'inn',\n",
       " 'inner',\n",
       " 'inse',\n",
       " 'insofar',\n",
       " 'into',\n",
       " 'inward',\n",
       " 'is',\n",
       " 'ise',\n",
       " 'isi',\n",
       " 'iska',\n",
       " 'iskaa',\n",
       " 'iske',\n",
       " 'iski',\n",
       " 'isme',\n",
       " 'isn',\n",
       " 'isne',\n",
       " 'isnt',\n",
       " \"isn't\",\n",
       " 'iss',\n",
       " 'isse',\n",
       " 'issi',\n",
       " 'isski',\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " 'itna',\n",
       " 'itne',\n",
       " 'itni',\n",
       " 'itno',\n",
       " 'its',\n",
       " \"it's\",\n",
       " 'itself',\n",
       " 'ityaadi',\n",
       " 'ityadi',\n",
       " \"i've\",\n",
       " 'ja',\n",
       " 'jaa',\n",
       " 'jab',\n",
       " 'jabh',\n",
       " 'jaha',\n",
       " 'jahaan',\n",
       " 'jahan',\n",
       " 'jaisa',\n",
       " 'jaise',\n",
       " 'jaisi',\n",
       " 'jata',\n",
       " 'jayega',\n",
       " 'jidhar',\n",
       " 'jin',\n",
       " 'jinhe',\n",
       " 'jinhi',\n",
       " 'jinho',\n",
       " 'jinhone',\n",
       " 'jinka',\n",
       " 'jinke',\n",
       " 'jinki',\n",
       " 'jinn',\n",
       " 'jis',\n",
       " 'jise',\n",
       " 'jiska',\n",
       " 'jiske',\n",
       " 'jiski',\n",
       " 'jisme',\n",
       " 'jiss',\n",
       " 'jisse',\n",
       " 'jitna',\n",
       " 'jitne',\n",
       " 'jitni',\n",
       " 'jo',\n",
       " 'just',\n",
       " 'jyaada',\n",
       " 'jyada',\n",
       " 'k',\n",
       " 'ka',\n",
       " 'kaafi',\n",
       " 'kab',\n",
       " 'kabhi',\n",
       " 'kafi',\n",
       " 'kaha',\n",
       " 'kahaa',\n",
       " 'kahaan',\n",
       " 'kahan',\n",
       " 'kahi',\n",
       " 'kahin',\n",
       " 'kahte',\n",
       " 'kaisa',\n",
       " 'kaise',\n",
       " 'kaisi',\n",
       " 'kal',\n",
       " 'kam',\n",
       " 'kar',\n",
       " 'kara',\n",
       " 'kare',\n",
       " 'karega',\n",
       " 'karegi',\n",
       " 'karen',\n",
       " 'karenge',\n",
       " 'kari',\n",
       " 'karke',\n",
       " 'karna',\n",
       " 'karne',\n",
       " 'karni',\n",
       " 'karo',\n",
       " 'karta',\n",
       " 'karte',\n",
       " 'karti',\n",
       " 'karu',\n",
       " 'karun',\n",
       " 'karunga',\n",
       " 'karungi',\n",
       " 'kaun',\n",
       " 'kaunsa',\n",
       " 'kayi',\n",
       " 'kch',\n",
       " 'ke',\n",
       " 'keep',\n",
       " 'keeps',\n",
       " 'keh',\n",
       " 'kehte',\n",
       " 'kept',\n",
       " 'khud',\n",
       " 'ki',\n",
       " 'kin',\n",
       " 'kine',\n",
       " 'kinhe',\n",
       " 'kinho',\n",
       " 'kinka',\n",
       " 'kinke',\n",
       " 'kinki',\n",
       " 'kinko',\n",
       " 'kinn',\n",
       " 'kino',\n",
       " 'kis',\n",
       " 'kise',\n",
       " 'kisi',\n",
       " 'kiska',\n",
       " 'kiske',\n",
       " 'kiski',\n",
       " 'kisko',\n",
       " 'kisliye',\n",
       " 'kisne',\n",
       " 'kitna',\n",
       " 'kitne',\n",
       " 'kitni',\n",
       " 'kitno',\n",
       " 'kiya',\n",
       " 'kiye',\n",
       " 'know',\n",
       " 'known',\n",
       " 'knows',\n",
       " 'ko',\n",
       " 'koi',\n",
       " 'kon',\n",
       " 'konsa',\n",
       " 'koyi',\n",
       " 'krna',\n",
       " 'krne',\n",
       " 'kuch',\n",
       " 'kuchch',\n",
       " 'kuchh',\n",
       " 'kul',\n",
       " 'kull',\n",
       " 'kya',\n",
       " 'kyaa',\n",
       " 'kyu',\n",
       " 'kyuki',\n",
       " 'kyun',\n",
       " 'kyunki',\n",
       " 'lagta',\n",
       " 'lagte',\n",
       " 'lagti',\n",
       " 'last',\n",
       " 'lately',\n",
       " 'later',\n",
       " 'le',\n",
       " 'least',\n",
       " 'lekar',\n",
       " 'lekin',\n",
       " 'less',\n",
       " 'lest',\n",
       " 'let',\n",
       " \"let's\",\n",
       " 'li',\n",
       " 'like',\n",
       " 'liked',\n",
       " 'likely',\n",
       " 'little',\n",
       " 'liya',\n",
       " 'liye',\n",
       " 'll',\n",
       " 'lo',\n",
       " 'log',\n",
       " 'logon',\n",
       " 'lol',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'looks',\n",
       " 'ltd',\n",
       " 'lunga',\n",
       " 'm',\n",
       " 'maan',\n",
       " 'maana',\n",
       " 'maane',\n",
       " 'maani',\n",
       " 'maano',\n",
       " 'magar',\n",
       " 'mai',\n",
       " 'main',\n",
       " 'maine',\n",
       " 'mainly',\n",
       " 'mana',\n",
       " 'mane',\n",
       " 'mani',\n",
       " 'mano',\n",
       " 'many',\n",
       " 'mat',\n",
       " 'may',\n",
       " 'maybe',\n",
       " 'me',\n",
       " 'mean',\n",
       " 'meanwhile',\n",
       " 'mein',\n",
       " 'mera',\n",
       " 'mere',\n",
       " 'merely',\n",
       " 'meri',\n",
       " 'might',\n",
       " 'mightn',\n",
       " 'mightnt',\n",
       " \"mightn't\",\n",
       " 'mil',\n",
       " 'mjhe',\n",
       " 'more',\n",
       " 'moreover',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'much',\n",
       " 'mujhe',\n",
       " 'must',\n",
       " 'mustn',\n",
       " 'mustnt',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'na',\n",
       " 'naa',\n",
       " 'naah',\n",
       " 'nahi',\n",
       " 'nahin',\n",
       " 'nai',\n",
       " 'name',\n",
       " 'namely',\n",
       " 'nd',\n",
       " 'ne',\n",
       " 'near',\n",
       " 'nearly',\n",
       " 'necessary',\n",
       " 'neeche',\n",
       " 'need',\n",
       " 'needn',\n",
       " 'neednt',\n",
       " \"needn't\",\n",
       " 'needs',\n",
       " 'neither',\n",
       " 'never',\n",
       " 'nevertheless',\n",
       " 'new',\n",
       " 'next',\n",
       " 'nhi',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'non',\n",
       " 'none',\n",
       " 'noone',\n",
       " 'nope',\n",
       " 'nor',\n",
       " 'normally',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'novel',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'o',\n",
       " 'obviously',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'okay',\n",
       " 'old',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'ones',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'or',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'ought',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'outside',\n",
       " 'over',\n",
       " 'overall',\n",
       " 'own',\n",
       " 'par',\n",
       " 'pata',\n",
       " 'pe',\n",
       " 'pehla',\n",
       " 'pehle',\n",
       " 'pehli',\n",
       " 'people',\n",
       " 'per',\n",
       " 'perhaps',\n",
       " 'phla',\n",
       " 'phle',\n",
       " 'phli',\n",
       " 'placed',\n",
       " 'please',\n",
       " 'plus',\n",
       " 'poora',\n",
       " 'poori',\n",
       " 'provides',\n",
       " 'pura',\n",
       " 'puri',\n",
       " 'q',\n",
       " 'que',\n",
       " 'quite',\n",
       " 'raha',\n",
       " 'rahaa',\n",
       " 'rahe',\n",
       " 'rahi',\n",
       " 'rakh',\n",
       " 'rakha',\n",
       " 'rakhe',\n",
       " 'rakhen',\n",
       " 'rakhi',\n",
       " 'rakho',\n",
       " 'rather',\n",
       " 're',\n",
       " 'really',\n",
       " 'reasonably',\n",
       " 'regarding',\n",
       " 'regardless',\n",
       " 'regards',\n",
       " 'rehte',\n",
       " 'rha',\n",
       " 'rhaa',\n",
       " 'rhe',\n",
       " 'rhi',\n",
       " 'ri',\n",
       " 'right',\n",
       " 's',\n",
       " 'sa',\n",
       " 'saara',\n",
       " 'saare',\n",
       " 'saath',\n",
       " 'sab',\n",
       " 'sabhi',\n",
       " 'sabse',\n",
       " 'sahi',\n",
       " 'said',\n",
       " 'sakta',\n",
       " 'saktaa',\n",
       " 'sakte',\n",
       " 'sakti',\n",
       " 'same',\n",
       " 'sang',\n",
       " 'sara',\n",
       " 'sath',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'saying',\n",
       " 'says',\n",
       " 'se',\n",
       " 'second',\n",
       " 'secondly',\n",
       " 'see',\n",
       " 'seeing',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seeming',\n",
       " 'seems',\n",
       " 'seen',\n",
       " 'self',\n",
       " 'selves',\n",
       " 'sensible',\n",
       " 'sent',\n",
       " 'serious',\n",
       " 'seriously',\n",
       " 'seven',\n",
       " 'several',\n",
       " 'shall',\n",
       " 'shan',\n",
       " 'shant',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " 'shouldnt',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'si',\n",
       " 'since',\n",
       " 'six',\n",
       " 'so',\n",
       " 'soch',\n",
       " 'some',\n",
       " 'somebody',\n",
       " 'somehow',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'sometime',\n",
       " 'sometimes',\n",
       " 'somewhat',\n",
       " 'somewhere',\n",
       " 'soon',\n",
       " 'still',\n",
       " 'sub',\n",
       " 'such',\n",
       " 'sup',\n",
       " 'sure',\n",
       " 't',\n",
       " 'tab',\n",
       " 'tabh',\n",
       " 'tak',\n",
       " 'take',\n",
       " 'taken',\n",
       " 'tarah',\n",
       " 'teen',\n",
       " 'teeno',\n",
       " 'teesra',\n",
       " 'teesre',\n",
       " 'teesri',\n",
       " 'tell',\n",
       " 'tends',\n",
       " 'tera',\n",
       " 'tere',\n",
       " 'teri',\n",
       " 'th',\n",
       " 'tha',\n",
       " 'than',\n",
       " 'thank',\n",
       " 'thanks',\n",
       " 'thanx',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'thats',\n",
       " \"that's\",\n",
       " 'the',\n",
       " 'theek',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'thence',\n",
       " 'there',\n",
       " 'thereafter',\n",
       " 'thereby',\n",
       " 'therefore',\n",
       " 'therein',\n",
       " 'theres',\n",
       " \"there's\",\n",
       " 'thereupon',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'thi',\n",
       " 'thik',\n",
       " 'thing',\n",
       " 'think',\n",
       " 'thinking',\n",
       " 'third',\n",
       " 'this',\n",
       " 'tho',\n",
       " 'thoda',\n",
       " 'thodi',\n",
       " 'thorough',\n",
       " 'thoroughly',\n",
       " 'those',\n",
       " 'though',\n",
       " 'thought',\n",
       " 'three',\n",
       " 'through',\n",
       " 'throughout',\n",
       " 'thru',\n",
       " 'thus',\n",
       " 'tjhe',\n",
       " 'to',\n",
       " 'together',\n",
       " 'toh',\n",
       " 'too',\n",
       " 'took',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'tried',\n",
       " 'tries',\n",
       " 'true',\n",
       " 'truly',\n",
       " 'try',\n",
       " 'trying',\n",
       " 'tu',\n",
       " 'tujhe',\n",
       " 'tum',\n",
       " 'tumhara',\n",
       " 'tumhare',\n",
       " 'tumhari',\n",
       " 'tune',\n",
       " 'twice',\n",
       " 'two',\n",
       " 'um',\n",
       " 'umm',\n",
       " 'un',\n",
       " 'under',\n",
       " 'unhe',\n",
       " 'unhi',\n",
       " 'unho',\n",
       " 'unhone',\n",
       " 'unka',\n",
       " 'unkaa',\n",
       " 'unke',\n",
       " 'unki',\n",
       " 'unko',\n",
       " 'unless',\n",
       " 'unlikely',\n",
       " 'unn',\n",
       " 'unse',\n",
       " 'until',\n",
       " 'unto',\n",
       " 'up',\n",
       " 'upar',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'use',\n",
       " 'used',\n",
       " 'useful',\n",
       " 'uses',\n",
       " 'usi',\n",
       " 'using',\n",
       " 'uska',\n",
       " 'uske',\n",
       " 'usne',\n",
       " 'uss',\n",
       " 'usse',\n",
       " 'ussi',\n",
       " 'usually',\n",
       " 'vaala',\n",
       " 'vaale',\n",
       " 'vaali',\n",
       " 'vahaan',\n",
       " 'vahan',\n",
       " 'vahi',\n",
       " 'vahin',\n",
       " 'vaisa',\n",
       " 'vaise',\n",
       " 'vaisi',\n",
       " 'vala',\n",
       " 'vale',\n",
       " 'vali',\n",
       " 'various',\n",
       " 've',\n",
       " 'very',\n",
       " 'via',\n",
       " 'viz',\n",
       " 'vo',\n",
       " 'waala',\n",
       " 'waale',\n",
       " 'waali',\n",
       " 'wagaira',\n",
       " 'wagairah',\n",
       " 'wagerah',\n",
       " 'waha',\n",
       " 'wahaan',\n",
       " 'wahan',\n",
       " 'wahi',\n",
       " 'wahin',\n",
       " 'waisa',\n",
       " 'waise',\n",
       " 'waisi',\n",
       " 'wala',\n",
       " 'wale',\n",
       " 'wali',\n",
       " 'want',\n",
       " 'wants',\n",
       " 'was',\n",
       " 'wasn',\n",
       " 'wasnt',\n",
       " \"wasn't\",\n",
       " 'way',\n",
       " 'we',\n",
       " \"we'd\",\n",
       " 'well',\n",
       " \"we'll\",\n",
       " 'went',\n",
       " 'were',\n",
       " \"we're\",\n",
       " 'weren',\n",
       " 'werent',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'whatever',\n",
       " \"what's\",\n",
       " 'when',\n",
       " 'whence',\n",
       " 'whenever',\n",
       " 'where',\n",
       " 'whereafter',\n",
       " 'whereas',\n",
       " 'whereby',\n",
       " 'wherein',\n",
       " \"where's\",\n",
       " 'whereupon',\n",
       " 'wherever',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whoever',\n",
       " 'whole',\n",
       " 'whom',\n",
       " \"who's\",\n",
       " 'whose',\n",
       " 'why',\n",
       " 'will',\n",
       " 'willing',\n",
       " 'with',\n",
       " 'within',\n",
       " ...]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('hinglish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c96720d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1036"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('hinglish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5168cd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    new_text = []\n",
    "    \n",
    "    for word in text.split():\n",
    "        if word in stopwords.words('english'):\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    x = new_text[:]\n",
    "    new_text.clear()\n",
    "    return \" \".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "18ebd0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes time to remove stopword\n",
    "# SHould be a better approach\n",
    "# data[\"review\"] = data[\"review\"].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ba00af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"hello how are you \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "47ac322d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\" \".join([t for t in x.split() if t not in stopwords.words('english')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f81f825d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[\"review\"] = data[\"review\"].apply(lambda x: \" \".join([t for t in x.split() if t not in stopwords.words(\"english\")]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe533fe0",
   "metadata": {},
   "source": [
    "# Dealing With Emojis 😊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "393bc425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Emojis\n",
    "import re\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a6596742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TIme for a quick coffee  break '"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_emoji(\"TIme for a quick coffee ☕ break 🍩\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9d820419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIme for a quick coffee :hot_beverage: break :doughnut:\n"
     ]
    }
   ],
   "source": [
    "# REplacing emojis with its meaning\n",
    "import emoji\n",
    "print(emoji.demojize(\"TIme for a quick coffee ☕ break 🍩\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c3f6be",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50233bd",
   "metadata": {},
   "source": [
    "**Issues tokenization faces are -** \n",
    "- Prefix: Characters at the begining\n",
    "- Suffix: Characters at the end\n",
    "- Infix: Characters in between\n",
    "- Exception: Special case rule to split a string into several tokens or prevent a token from bing split when punctuation rules are applied\n",
    "- examples: $20, 15KM, let's, U.S. -,_,/,!,), new-delhi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc94f514",
   "metadata": {},
   "source": [
    "## 1. Using the split function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9896c12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word tokenization\n",
    "sent1 = 'I am going to delhi'\n",
    "sent1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bc12dc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am going to delhi',\n",
       " ' I will stay there for 3 days',\n",
       " \" Let's hope the trip to be great\"]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence tokenization\n",
    "sent2 = 'I am going to delhi. I will stay there for 3 days. Let\\'s hope the trip to be great'\n",
    "sent2.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ae93315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I', 'am', 'going', 'to', 'delhi'],\n",
       " ['I', 'will', 'stay', 'there', 'for', '3', 'days'],\n",
       " [\"Let's\", 'hope', 'the', 'trip', 'to', 'be', 'great']]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sentence word level tokenization\n",
    "sent_lst = []\n",
    "for sent in sent2.split('.'):\n",
    "    sent_lst.append(sent.split())\n",
    "sent_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "149ddbc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi!']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problems with split function\n",
    "sent3 = 'I am going to delhi!'\n",
    "sent3.split()\n",
    "# delhi has ! with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aaca6da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Where do think I should go? I have 3 day holiday']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent4 = 'Where do think I should go? I have 3 day holiday'\n",
    "sent4.split('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b7148f",
   "metadata": {},
   "source": [
    "## 2. Regular Expressions\n",
    "- Better than split. Here you have to look for the patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ce822cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "sent3 = 'I am going to delhi!'\n",
    "tokens = re.findall(\"[\\w']+\", sent3)\n",
    "tokens\n",
    "# ! is removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0f539730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Let's\", 'go', 'to', 'delhi']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent3 = \"Let's go to delhi!\"\n",
    "tokens = re.findall(\"[\\w']+\", sent3)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d5120a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem Ipsum is simply dummy text of the printing and typesetting industry',\n",
       " \"\\nLorem Ipsum has been the industry's standard dummy text ever since the 1500s, \\nwhen an unknown printer took a galley of type and scrambled it to make a type specimen book.\"]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"Lorem Ipsum is simply dummy text of the printing and typesetting industry? \n",
    "Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, \n",
    "when an unknown printer took a galley of type and scrambled it to make a type specimen book.\"\"\"\n",
    "sentences = re.compile('[.!?] ').split(text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f971686",
   "metadata": {},
   "source": [
    "# 3. NLTK\n",
    "- Use libraries where ever possible. Spacy is the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "326cebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e664c4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'visit', 'delhi', '!']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = 'I am going to visit delhi!'\n",
    "word_tokenize(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2fad3327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem Ipsum is simply dummy text of the printing and typesetting industry?',\n",
       " \"Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, \\nwhen an unknown printer took a galley of type and scrambled it to make a type specimen book.\"]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"Lorem Ipsum is simply dummy text of the printing and typesetting industry? \n",
    "Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, \n",
    "when an unknown printer took a galley of type and scrambled it to make a type specimen book.\"\"\"\n",
    "\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "808cf792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'have', 'a', 'Ph.D', 'in', 'A.I']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent5 = 'I have a Ph.D in A.I'\n",
    "sent6 = \"We're here to help! mail us at robin@gmail.com\"\n",
    "sent7 = 'A 5km ride cost $10.50'\n",
    "\n",
    "word_tokenize(sent5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "83d3824e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We',\n",
       " \"'re\",\n",
       " 'here',\n",
       " 'to',\n",
       " 'help',\n",
       " '!',\n",
       " 'mail',\n",
       " 'us',\n",
       " 'at',\n",
       " 'robin',\n",
       " '@',\n",
       " 'gmail.com']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "166c2eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', '5km', 'ride', 'cost', '$', '10.50']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524d68fd",
   "metadata": {},
   "source": [
    "# 4. Spacy \n",
    "- Best library for tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "63f0f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ef81b092",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(sent5)\n",
    "doc2 = nlp(sent6)\n",
    "doc3 = nlp(sent7)\n",
    "doc4 = nlp(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "16e3c540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "have\n",
      "a\n",
      "Ph\n",
      ".\n",
      "D\n",
      "in\n",
      "A.I\n"
     ]
    }
   ],
   "source": [
    "for token in doc1:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d6e9df",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "- In grammar, inflection is the modification of a word to express different grammatical categories such as tense, case, voice, ascpect, person, number, gender & mood.\n",
    "- Examples: walk, walking, walked, walks, do, undoable, redo\n",
    "\n",
    "**Stemming -root-word** Stemming is the process of reducing inflection in words to their root forms such as mapping a group of words to the same stem even if the stem itself is not a valid word in the language\n",
    "- Stemming is very useful in Information Retrieval system such as search engines.\n",
    "- Stemmer - algos used for stemming. NLTK - Porter stemmer & snowball stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "56452ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "64d853bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "001cf1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_words(text):\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4e2198e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I walk daily as walking is good for health. I even walked yday\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "582235ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i walk daili as walk is good for health. i even walk yday'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_words(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ee3d4114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One thing to keep in mind is root word from stemming might does not make any sense. like daili\n",
    "# Hence we use lemmatization. Only issue with lemmetization is, it is slow in processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97385385",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "- Lemmatization, unlike stemming, reduces the inflexted words  properly ensuring that the root word belongs to the language. In Lemmatization root wor is called Lemma. A lemma - (plural lemmas or lemmata), is the canonical form, dictionary form, or citation form of a set of words.\n",
    "\n",
    "**Wordnet lemmatization** is a lexical dictionary. It has information on how different words are related to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "91eb2387",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9eea4515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Lemma               \n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Admin/nltk_data'\n    - 'C:\\\\Users\\\\Admin\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Admin\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\Admin\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Admin\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 84\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4.zip/omw-1.4/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Admin/nltk_data'\n    - 'C:\\\\Users\\\\Admin\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Admin\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\Admin\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Admin\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0:20}\u001b[39;00m\u001b[38;5;132;01m{1:20}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWord\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLemma\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sentence_words:\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0:20}\u001b[39;00m\u001b[38;5;132;01m{1:20}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(word,\u001b[43mwordnet_lemmatizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlemmatize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\stem\\wordnet.py:45\u001b[0m, in \u001b[0;36mWordNetLemmatizer.lemmatize\u001b[1;34m(self, word, pos)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlemmatize\u001b[39m(\u001b[38;5;28mself\u001b[39m, word: \u001b[38;5;28mstr\u001b[39m, pos: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m     34\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Lemmatize `word` using WordNet's built-in morphy function.\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m    Returns the input word unchanged if it cannot be found in WordNet.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03m    :return: The lemma of `word`, for the given `pos`.\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m     lemmas \u001b[38;5;241m=\u001b[39m \u001b[43mwn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_morphy\u001b[49m(word, pos)\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(lemmas, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m lemmas \u001b[38;5;28;01melse\u001b[39;00m word\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py:89\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# This is where the magic happens!  Transform ourselves into\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# the corpus by modifying our own __dict__ and __class__ to\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# match that of the corpus.\u001b[39;00m\n\u001b[0;32m     95\u001b[0m args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py:1176\u001b[0m, in \u001b[0;36mWordNetCorpusReader.__init__\u001b[1;34m(self, root, omw_reader)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe multilingual functions are not available with this Wordnet version\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1174\u001b[0m     )\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprovenances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43momw_prov\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;66;03m# A cache to store the wordnet data of multiple languages\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lang_data \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py:1285\u001b[0m, in \u001b[0;36mWordNetCorpusReader.omw_prov\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1283\u001b[0m provdict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1284\u001b[0m provdict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1285\u001b[0m fileids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_omw_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfileids\u001b[49m()\n\u001b[0;32m   1286\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fileid \u001b[38;5;129;01min\u001b[39;00m fileids:\n\u001b[0;32m   1287\u001b[0m     prov, langfile \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplit(fileid)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m             root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[0;32m     89\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Admin/nltk_data'\n    - 'C:\\\\Users\\\\Admin\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Admin\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\Admin\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Admin\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "sentence = \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\"\n",
    "punctuations=\"?:!.,;\"\n",
    "sentence_words = nltk.word_tokenize(sentence)\n",
    "for word in sentence_words:\n",
    "    if word in punctuations:\n",
    "        sentence_words.remove(word)\n",
    "\n",
    "sentence_words\n",
    "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
    "for word in sentence_words:\n",
    "    print (\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word,pos='v')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b4fbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "print(nltk.find('corpora/wordnet.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "76f88034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"genres\":[{\"id\":28,\"name\":\"Action\"},{\"id\":12,\"name\":\"Adventure\"},{\"id\":16,\"name\":\"Animation\"},{\"id\":35,\"name\":\"Comedy\"},{\"id\":80,\"name\":\"Crime\"},{\"id\":99,\"name\":\"Documentary\"},{\"id\":18,\"name\":\"Drama\"},{\"id\":10751,\"name\":\"Family\"},{\"id\":14,\"name\":\"Fantasy\"},{\"id\":36,\"name\":\"History\"},{\"id\":27,\"name\":\"Horror\"},{\"id\":10402,\"name\":\"Music\"},{\"id\":9648,\"name\":\"Mystery\"},{\"id\":10749,\"name\":\"Romance\"},{\"id\":878,\"name\":\"Science Fiction\"},{\"id\":10770,\"name\":\"TV Movie\"},{\"id\":53,\"name\":\"Thriller\"},{\"id\":10752,\"name\":\"War\"},{\"id\":37,\"name\":\"Western\"}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.themoviedb.org/3/genre/movie/list?language=en\"\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer eyJhbGciOiJIUzI1NiJ9.eyJhdWQiOiI0YjY5ZDI4ZWQzYTI2NGQ0MGY1ZWE5MDNlMWI4MDVlMiIsInN1YiI6IjYyZGU4YTM3ZGMxY2I0MDA0Yzc3MjgyMiIsInNjb3BlcyI6WyJhcGlfcmVhZCJdLCJ2ZXJzaW9uIjoxfQ.0Hinwq3mTb8DnfVg49BS4oJkxzXFiLv7HA03kEG2pQU\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b197779d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"page\":1,\"results\":[{\"adult\":false,\"backdrop_path\":\"/tmU7GeKVybMWFButWEGl2M4GeiP.jpg\",\"genre_ids\":[18,80],\"id\":238,\"original_language\":\"en\",\"original_title\":\"The Godfather\",\"overview\":\"Spanning the years 1945 to 1955, a chronicle of the fictional Italian-American Corleone crime family. When organized crime family patriarch, Vito Corleone barely survives an attempt on his life, his youngest son, Michael steps in to take care of the would-be killers, launching a campaign of bloody revenge.\",\"popularity\":124.761,\"poster_path\":\"/3bhkrj58Vtu7enYsRolD1fZdja1.jpg\",\"release_date\":\"1972-03-14\",\"title\":\"The Godfather\",\"video\":false,\"vote_average\":8.708,\"vote_count\":19066},{\"adult\":false,\"backdrop_path\":\"/kXfqcdQKsToO0OUXHcrrNCHDBzO.jpg\",\"genre_ids\":[18,80],\"id\":278,\"original_language\":\"en\",\"original_title\":\"The Shawshank Redemption\",\"overview\":\"Framed in the 1940s for the double murder of his wife and her lover, upstanding banker Andy Dufresne begins a new life at the Shawshank prison, where he puts his accounting skills to work for an amoral warden. During his long stretch in prison, Dufresne comes to be admired by the other inmates -- including an older prisoner named Red -- for his integrity and unquenchable sense of hope.\",\"popularity\":102.922,\"poster_path\":\"/q6y0Go1tsGEsmtFryDOJo3dEmqu.jpg\",\"release_date\":\"1994-09-23\",\"title\":\"The Shawshank Redemption\",\"video\":false,\"vote_average\":8.706,\"vote_count\":25058},{\"adult\":false,\"backdrop_path\":\"/kGzFbGhp99zva6oZODW5atUtnqi.jpg\",\"genre_ids\":[18,80],\"id\":240,\"original_language\":\"en\",\"original_title\":\"The Godfather Part II\",\"overview\":\"In the continuing saga of the Corleone crime family, a young Vito Corleone grows up in Sicily and in 1910s New York. In the 1950s, Michael Corleone attempts to expand the family business into Las Vegas, Hollywood and Cuba.\",\"popularity\":66.712,\"poster_path\":\"/hek3koDUyRQk7FIhPXsa6mT2Zc3.jpg\",\"release_date\":\"1974-12-20\",\"title\":\"The Godfather Part II\",\"video\":false,\"vote_average\":8.59,\"vote_count\":11506},{\"adult\":false,\"backdrop_path\":\"/3f92DMBTFqr3wgXpfxzrb0qv8nG.jpg\",\"genre_ids\":[18,36,10752],\"id\":424,\"original_language\":\"en\",\"original_title\":\"Schindler's List\",\"overview\":\"The true story of how businessman Oskar Schindler saved over a thousand Jewish lives from the Nazis while they worked as slaves in his factory during World War II.\",\"popularity\":65.052,\"poster_path\":\"/sF1U4EUQS8YHUYjNl3pMGNIQyr0.jpg\",\"release_date\":\"1993-12-15\",\"title\":\"Schindler's List\",\"video\":false,\"vote_average\":8.572,\"vote_count\":14850},{\"adult\":false,\"backdrop_path\":\"/90ez6ArvpO8bvpyIngBuwXOqJm5.jpg\",\"genre_ids\":[35,18,10749],\"id\":19404,\"original_language\":\"hi\",\"original_title\":\"दिलवाले दुल्हनिया ले जायेंगे\",\"overview\":\"Raj is a rich, carefree, happy-go-lucky second generation NRI. Simran is the daughter of Chaudhary Baldev Singh, who in spite of being an NRI is very strict about adherence to Indian values. Simran has left for India to be married to her childhood fiancé. Raj leaves for India with a mission at his hands, to claim his lady love under the noses of her whole family. Thus begins a saga.\",\"popularity\":34.886,\"poster_path\":\"/ktejodbcdCPXbMMdnpI9BUxW6O8.jpg\",\"release_date\":\"1995-10-20\",\"title\":\"Dilwale Dulhania Le Jayenge\",\"video\":false,\"vote_average\":8.5,\"vote_count\":4293},{\"adult\":false,\"backdrop_path\":\"/qqHQsStV6exghCM7zbObuYBiYxw.jpg\",\"genre_ids\":[18],\"id\":389,\"original_language\":\"en\",\"original_title\":\"12 Angry Men\",\"overview\":\"The defense and the prosecution have rested and the jury is filing into the jury room to decide if a young Spanish-American is guilty or innocent of murdering his father. What begins as an open and shut case soon becomes a mini-drama of each of the jurors' prejudices and preconceptions about the trial, the accused, and each other.\",\"popularity\":43.427,\"poster_path\":\"/ow3wq89wM8qd5X7hWKxiRfsFf9C.jpg\",\"release_date\":\"1957-04-10\",\"title\":\"12 Angry Men\",\"video\":false,\"vote_average\":8.545,\"vote_count\":7837},{\"adult\":false,\"backdrop_path\":\"/mSDsSDwaP3E7dEfUPWy4J0djt4O.jpg\",\"genre_ids\":[16,10751,14],\"id\":129,\"original_language\":\"ja\",\"original_title\":\"千と千尋の神隠し\",\"overview\":\"A young girl, Chihiro, becomes trapped in a strange new world of spirits. When her parents undergo a mysterious transformation, she must call upon the courage she never knew she had to free her family.\",\"popularity\":92.068,\"poster_path\":\"/39wmItIWsg5sZMyRUHLkWBcuVCM.jpg\",\"release_date\":\"2001-07-20\",\"title\":\"Spirited Away\",\"video\":false,\"vote_average\":8.54,\"vote_count\":15185},{\"adult\":false,\"backdrop_path\":\"/hiKmpZMGZsrkA3cdce8a7Dpos1j.jpg\",\"genre_ids\":[35,53,18],\"id\":496243,\"original_language\":\"ko\",\"original_title\":\"기생충\",\"overview\":\"All unemployed, Ki-taek's family takes peculiar interest in the wealthy and glamorous Parks for their livelihood until they get entangled in an unexpected incident.\",\"popularity\":86.438,\"poster_path\":\"/7IiTTgloJzvGI1TAYymCfbfl3vT.jpg\",\"release_date\":\"2019-05-30\",\"title\":\"Parasite\",\"video\":false,\"vote_average\":8.514,\"vote_count\":16743},{\"adult\":false,\"backdrop_path\":\"/nMKdUUepR0i5zn0y1T4CsSB5chy.jpg\",\"genre_ids\":[18,28,80,53],\"id\":155,\"original_language\":\"en\",\"original_title\":\"The Dark Knight\",\"overview\":\"Batman raises the stakes in his war on crime. With the help of Lt. Jim Gordon and District Attorney Harvey Dent, Batman sets out to dismantle the remaining criminal organizations that plague the streets. The partnership proves to be effective, but they soon find themselves prey to a reign of chaos unleashed by a rising criminal mastermind known to the terrified citizens of Gotham as the Joker.\",\"popularity\":96.11,\"poster_path\":\"/qJ2tW6WMUDux911r6m7haRef0WH.jpg\",\"release_date\":\"2008-07-16\",\"title\":\"The Dark Knight\",\"video\":false,\"vote_average\":8.513,\"vote_count\":31020},{\"adult\":false,\"backdrop_path\":\"/l6hQWH9eDksNJNiXWYRkWqikOdu.jpg\",\"genre_ids\":[14,18,80],\"id\":497,\"original_language\":\"en\",\"original_title\":\"The Green Mile\",\"overview\":\"A supernatural tale set on death row in a Southern prison, where gentle giant John Coffey possesses the mysterious power to heal people's ailments. When the cell block's head guard, Paul Edgecomb, recognizes Coffey's miraculous gift, he tries desperately to help stave off the condemned man's execution.\",\"popularity\":60.99,\"poster_path\":\"/8VG8fDNiy50H4FedGwdSVUPoaJe.jpg\",\"release_date\":\"1999-12-10\",\"title\":\"The Green Mile\",\"video\":false,\"vote_average\":8.509,\"vote_count\":16201},{\"adult\":false,\"backdrop_path\":\"/dIWwZW7dJJtqC6CgWzYkNVKIUm8.jpg\",\"genre_ids\":[10749,16,18],\"id\":372058,\"original_language\":\"ja\",\"original_title\":\"君の名は。\",\"overview\":\"High schoolers Mitsuha and Taki are complete strangers living separate lives. But one night, they suddenly switch places. Mitsuha wakes up in Taki’s body, and he in hers. This bizarre occurrence continues to happen randomly, and the two must adjust their lives around each other.\",\"popularity\":79.588,\"poster_path\":\"/q719jXXEzOoYaps6babgKnONONX.jpg\",\"release_date\":\"2016-08-26\",\"title\":\"Your Name.\",\"video\":false,\"vote_average\":8.503,\"vote_count\":10550},{\"adult\":false,\"backdrop_path\":\"/suaEOtk1N1sgg2MTM7oZd2cfVp3.jpg\",\"genre_ids\":[53,80],\"id\":680,\"original_language\":\"en\",\"original_title\":\"Pulp Fiction\",\"overview\":\"A burger-loving hit man, his philosophical partner, a drug-addled gangster's moll and a washed-up boxer converge in this sprawling, comedic crime caper. Their adventures unfurl in three stories that ingeniously trip back and forth in time.\",\"popularity\":64.479,\"poster_path\":\"/d5iIlFn5s0ImszYzBPb8JPIfbXD.jpg\",\"release_date\":\"1994-09-10\",\"title\":\"Pulp Fiction\",\"video\":false,\"vote_average\":8.489,\"vote_count\":26231},{\"adult\":false,\"backdrop_path\":\"/9DeGfFIqjph5CBFVQrD6wv9S7rR.jpg\",\"genre_ids\":[12,14,28],\"id\":122,\"original_language\":\"en\",\"original_title\":\"The Lord of the Rings: The Return of the King\",\"overview\":\"Aragorn is revealed as the heir to the ancient kings as he, Gandalf and the other members of the broken fellowship struggle to save Gondor from Sauron's forces. Meanwhile, Frodo and Sam take the ring closer to the heart of Mordor, the dark lord's realm.\",\"popularity\":85.029,\"poster_path\":\"/rCzpDGLbOoPwLjy3OAm5NUPOTrC.jpg\",\"release_date\":\"2003-12-01\",\"title\":\"The Lord of the Rings: The Return of the King\",\"video\":false,\"vote_average\":8.476,\"vote_count\":22664},{\"adult\":false,\"backdrop_path\":\"/qdIMHd4sEfJSckfVJfKQvisL02a.jpg\",\"genre_ids\":[35,18,10749],\"id\":13,\"original_language\":\"en\",\"original_title\":\"Forrest Gump\",\"overview\":\"A man with a low IQ has accomplished great things in his life and been present during significant historic events—in each case, far exceeding what anyone imagined he could do. But despite all he has achieved, his one true love eludes him.\",\"popularity\":80.369,\"poster_path\":\"/arw2vcBveWOVZr6pxd9XTd1TdQa.jpg\",\"release_date\":\"1994-06-23\",\"title\":\"Forrest Gump\",\"video\":false,\"vote_average\":8.476,\"vote_count\":25758},{\"adult\":false,\"backdrop_path\":\"/eoCSp75lxatmIa6aGqfnzwtbttd.jpg\",\"genre_ids\":[37],\"id\":429,\"original_language\":\"it\",\"original_title\":\"Il buono, il brutto, il cattivo\",\"overview\":\"While the Civil War rages on between the Union and the Confederacy, three men – a quiet loner, a ruthless hitman, and a Mexican bandit – comb the American Southwest in search of a strongbox containing $200,000 in stolen gold.\",\"popularity\":67.889,\"poster_path\":\"/bX2xnavhMYjWDoZp1VM6VnU1xwe.jpg\",\"release_date\":\"1966-12-23\",\"title\":\"The Good, the Bad and the Ugly\",\"video\":false,\"vote_average\":8.471,\"vote_count\":7916},{\"adult\":false,\"backdrop_path\":\"/sw7mordbZxgITU877yTpZCud90M.jpg\",\"genre_ids\":[18,80],\"id\":769,\"original_language\":\"en\",\"original_title\":\"GoodFellas\",\"overview\":\"The true story of Henry Hill, a half-Irish, half-Sicilian Brooklyn kid who is adopted by neighbourhood gangsters at an early age and climbs the ranks of a Mafia family under the guidance of Jimmy Conway.\",\"popularity\":62.243,\"poster_path\":\"/aKuFiU82s5ISJpGZp7YkIr3kCUd.jpg\",\"release_date\":\"1990-09-12\",\"title\":\"GoodFellas\",\"video\":false,\"vote_average\":8.466,\"vote_count\":11943},{\"adult\":false,\"backdrop_path\":\"/dlC0ed9Ugh3FzydnkBtV5lRXUu4.jpg\",\"genre_ids\":[16,18,10752],\"id\":12477,\"original_language\":\"ja\",\"original_title\":\"火垂るの墓\",\"overview\":\"In the final months of World War II, 14-year-old Seita and his sister Setsuko are orphaned when their mother is killed during an air raid in Kobe, Japan. After a falling out with their aunt, they move into an abandoned bomb shelter. With no surviving relatives and their emergency rations depleted, Seita and Setsuko struggle to survive.\",\"popularity\":0.6,\"poster_path\":\"/k9tv1rXZbOhH7eiCk378x61kNQ1.jpg\",\"release_date\":\"1988-04-15\",\"title\":\"Grave of the Fireflies\",\"video\":false,\"vote_average\":8.455,\"vote_count\":4972},{\"adult\":false,\"backdrop_path\":\"/gavyCu1UaTaTNPsVaGXT6pe5u24.jpg\",\"genre_ids\":[35,18],\"id\":637,\"original_language\":\"it\",\"original_title\":\"La vita è bella\",\"overview\":\"A touching story of an Italian book seller of Jewish ancestry who lives in his own little fairy tale. His creative and happy life would come to an abrupt halt when his entire family is deported to a concentration camp during World War II. While locked up he tries to convince his son that the whole thing is just a game.\",\"popularity\":41.227,\"poster_path\":\"/6tEJnof1DKWPnl5lzkjf0FVv7oB.jpg\",\"release_date\":\"1997-12-20\",\"title\":\"Life Is Beautiful\",\"video\":false,\"vote_average\":8.455,\"vote_count\":12384},{\"adult\":false,\"backdrop_path\":\"/qvZ91FwMq6O47VViAr8vZNQz3WI.jpg\",\"genre_ids\":[28,18],\"id\":346,\"original_language\":\"ja\",\"original_title\":\"七人の侍\",\"overview\":\"A samurai answers a village's request for protection after he falls on hard times. The town needs protection from bandits, so the samurai gathers six others to help him teach the people how to defend themselves, and the villagers provide the soldiers with food.\",\"popularity\":35.802,\"poster_path\":\"/ApdijpVm1GNV9BQMOsGcAXq4gEB.jpg\",\"release_date\":\"1954-04-26\",\"title\":\"Seven Samurai\",\"video\":false,\"vote_average\":8.455,\"vote_count\":3305},{\"adult\":false,\"backdrop_path\":\"/zoVeIgKzGJzpdG6Gwnr7iOYfIMU.jpg\",\"genre_ids\":[18,10749],\"id\":11216,\"original_language\":\"it\",\"original_title\":\"Nuovo Cinema Paradiso\",\"overview\":\"A filmmaker recalls his childhood, when he fell in love with the movies at his village's theater and formed a deep friendship with the theater's projectionist.\",\"popularity\":28.454,\"poster_path\":\"/8SRUfRUi6x4O68n0VCbDNRa6iGL.jpg\",\"release_date\":\"1988-11-17\",\"title\":\"Cinema Paradiso\",\"video\":false,\"vote_average\":8.448,\"vote_count\":4028}],\"total_pages\":450,\"total_results\":8994}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.themoviedb.org/3/movie/top_rated?language=en-US&page=1\"\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer eyJhbGciOiJIUzI1NiJ9.eyJhdWQiOiI0YjY5ZDI4ZWQzYTI2NGQ0MGY1ZWE5MDNlMWI4MDVlMiIsInN1YiI6IjYyZGU4YTM3ZGMxY2I0MDA0Yzc3MjgyMiIsInNjb3BlcyI6WyJhcGlfcmVhZCJdLCJ2ZXJzaW9uIjoxfQ.0Hinwq3mTb8DnfVg49BS4oJkxzXFiLv7HA03kEG2pQU\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "494c66d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'json'"
     ]
    }
   ],
   "source": [
    "response.text.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6434b24c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
