{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "690034b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(101)\n",
    "\n",
    "import sklearn\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12ed3c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version is 2.14.0\n",
      "sklearn version is 1.2.1\n"
     ]
    }
   ],
   "source": [
    "print(f'tensorflow version is {tf.__version__}')\n",
    "print(f'sklearn version is {sklearn.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5695f26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/ner_datasetreference.csv\",encoding='unicode_escape')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6012a946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048575, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45c78493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000616"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Sentence #\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5481d857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence #    1000616\n",
       "Word                0\n",
       "POS                 0\n",
       "Tag                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e759ca5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN      145807\n",
       "NNP     131426\n",
       "IN      120996\n",
       "DT       98454\n",
       "JJ       78412\n",
       "NNS      75840\n",
       ".        47831\n",
       "VBD      39379\n",
       ",        32757\n",
       "VBN      32328\n",
       "VBZ      24960\n",
       "CD       24695\n",
       "VB       24211\n",
       "CC       23716\n",
       "TO       23061\n",
       "RB       20252\n",
       "VBG      19125\n",
       "VBP      16158\n",
       "PRP      13318\n",
       "POS      11257\n",
       "PRP$      8655\n",
       "MD        6973\n",
       "``        3728\n",
       "WDT       3698\n",
       "JJS       3034\n",
       "JJR       2967\n",
       "WP        2542\n",
       "NNPS      2521\n",
       "RP        2490\n",
       "WRB       2184\n",
       "$         1149\n",
       "RBR       1055\n",
       ":          795\n",
       "RRB        679\n",
       "LRB        678\n",
       "EX         663\n",
       "RBS        296\n",
       ";          214\n",
       "PDT        147\n",
       "WP$         99\n",
       "UH          24\n",
       "FW           1\n",
       "Name: POS, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"POS\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ffae686b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['O', 'B-geo', 'B-tim', 'B-org', 'I-per', 'B-per', 'I-org', 'B-gpe',\n",
       "       'I-geo', 'I-tim', 'B-art', 'B-eve', 'I-art', 'I-eve', 'B-nat', 'I-gpe',\n",
       "       'I-nat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Tag\"].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06ada795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>London</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hyde</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Britain</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #      Word  POS    Tag\n",
       "6          NaN    London  NNP  B-geo\n",
       "12         NaN      Iraq  NNP  B-geo\n",
       "65         NaN      Hyde  NNP  B-geo\n",
       "94         NaN   Britain  NNP  B-geo\n",
       "106        NaN  Brighton  NNP  B-geo"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"Tag\"]==\"B-geo\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "41c4f0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[(data[\"Tag\"]==i and data[\"Tag\"]!=\"O\") ]\n",
    "#(data[\"Tag\"]==i and data[\"Tag\"]!=\"O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "88ed13a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-geo\n",
      "   Sentence #    Word  POS    Tag\n",
      "6         NaN  London  NNP  B-geo\n",
      "12        NaN    Iraq  NNP  B-geo\n",
      "\n",
      "B-tim\n",
      "    Sentence #       Word  POS    Tag\n",
      "167        NaN  Wednesday  NNP  B-tim\n",
      "211        NaN  Wednesday  NNP  B-tim\n",
      "\n",
      "B-org\n",
      "    Sentence #           Word  POS    Tag\n",
      "97         NaN          Labor  NNP  B-org\n",
      "154        NaN  International  NNP  B-org\n",
      "\n",
      "I-per\n",
      "    Sentence #         Word  POS    Tag\n",
      "271        NaN      Mahmoud  NNP  I-per\n",
      "272        NaN  Ahmadinejad  NNP  I-per\n",
      "\n",
      "B-per\n",
      "    Sentence #       Word  POS    Tag\n",
      "42         NaN       Bush  NNP  B-per\n",
      "270        NaN  President  NNP  B-per\n",
      "\n",
      "I-org\n",
      "    Sentence #    Word  POS    Tag\n",
      "98         NaN   Party  NNP  I-org\n",
      "155        NaN  Atomic  NNP  I-org\n",
      "\n",
      "B-gpe\n",
      "    Sentence #     Word POS    Tag\n",
      "18         NaN  British  JJ  B-gpe\n",
      "102        NaN  English  JJ  B-gpe\n",
      "\n",
      "I-geo\n",
      "    Sentence #   Word  POS    Tag\n",
      "66         NaN   Park  NNP  I-geo\n",
      "347        NaN  State  NNP  I-geo\n",
      "\n",
      "I-tim\n",
      "     Sentence # Word POS    Tag\n",
      "1479        NaN    8  CD  I-tim\n",
      "1993        NaN    1  CD  I-tim\n",
      "\n",
      "B-art\n",
      "     Sentence #      Word  POS    Tag\n",
      "263         NaN   Nuclear  NNP  B-art\n",
      "3769        NaN  Saltillo  NNP  B-art\n",
      "\n",
      "B-eve\n",
      "     Sentence #   Word   POS    Tag\n",
      "4853        NaN   2012    CD  B-eve\n",
      "4887        NaN  Games  NNPS  B-eve\n",
      "\n",
      "I-art\n",
      "     Sentence #               Word  POS    Tag\n",
      "264         NaN  Non-Proliferation  NNP  I-art\n",
      "3811        NaN                V-6  NNP  I-art\n",
      "\n",
      "I-eve\n",
      "     Sentence #      Word   POS    Tag\n",
      "4854        NaN    Summer   NNP  I-eve\n",
      "4855        NaN  Olympics  NNPS  I-eve\n",
      "\n",
      "B-nat\n",
      "     Sentence #  Word  POS    Tag\n",
      "2723        NaN  H5N1  NNP  B-nat\n",
      "4554        NaN  H5N1  NNP  B-nat\n",
      "\n",
      "I-gpe\n",
      "     Sentence #    Word   POS    Tag\n",
      "1225        NaN  States  NNPS  I-gpe\n",
      "1264        NaN   Korea   NNP  I-gpe\n",
      "\n",
      "I-nat\n",
      "     Sentence #  Word  POS    Tag\n",
      "5045        NaN  Jing  NNP  I-nat\n",
      "5074        NaN  Jing  NNP  I-nat\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in data[\"Tag\"].value_counts().index[1:]:\n",
    "    print(i)\n",
    "    try:\n",
    "        print(data[(data[\"Tag\"]==i)].head(2))\n",
    "    except:\n",
    "        print()\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0eaa00d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Thousands\n",
       "1               of\n",
       "2    demonstrators\n",
       "3             have\n",
       "4          marched\n",
       "5          through\n",
       "6           London\n",
       "7               to\n",
       "8          protest\n",
       "9              the\n",
       "Name: Word, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Word\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12075bd",
   "metadata": {},
   "source": [
    "# Name Entity Recognition\n",
    "\n",
    "NER is a subtask of information extraction that locates and classifies named entities in a text. The named entities could be organizations, persons, locations, times, etc.\n",
    "\n",
    "For example,\n",
    "\n",
    "Hydroxychloroquine has been studied for the treatment and prevention of coronavirus disease 2019. The named entities in this sentence are\n",
    "\n",
    "- Hydroxychloroquine - Drugs\n",
    "- coronavirus disease - Diseases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ef1db0",
   "metadata": {},
   "source": [
    "# Formulate an NER Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9b704",
   "metadata": {},
   "source": [
    "- Define the entity classes you want to extract. For example, gene, disease, drug, etc.\n",
    "- Collect relevant text data and annotate the data\n",
    "- Train NER model to predict those entities and classify them into the given categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a14b42",
   "metadata": {},
   "source": [
    "# Sequence Model Approach to NER\n",
    "**Training**\n",
    "- Collect a set of representative training examples (documents)\n",
    "- Annotate each token for its entity class or other (O) using BIO encoding scheme\n",
    "- Feature engineering\n",
    "- Train a sequence tagger to predict the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9ec93b",
   "metadata": {},
   "source": [
    "**Test**\n",
    "- Receive/sample a set of test examples\n",
    "- Run sequence model inference to label each token\n",
    "- Return the recognized entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828fc6ab",
   "metadata": {},
   "source": [
    "In natural language processing (NLP), particularly in Named Entity Recognition (NER) tasks, the BIO (Begin, Inside, Outside) tagging scheme is commonly used to annotate and encode sequences of words or tokens to indicate the boundaries of named entities within the text. The BIO scheme is used for labeling each token in a sequence as the beginning of an entity (B), inside an entity (I), or outside an entity (O).\n",
    "\n",
    "### Encoding in the BIO Scheme:\n",
    "\n",
    "- **B (Begin):** Indicates the beginning of an entity within a sequence. It marks the first token of a named entity.\n",
    "\n",
    "- **I (Inside):** Indicates tokens inside an entity other than the first token. It follows a \"B\" tag and identifies subsequent tokens that are part of the same entity.\n",
    "\n",
    "- **O (Outside):** Represents tokens that are not part of any named entity.\n",
    "\n",
    "### Example of BIO Encoding:\n",
    "\n",
    "Consider the sentence: \"John Smith works at Google in New York.\"\n",
    "\n",
    "For a named entity recognition task targeting entities like person names, organizations, and locations, the BIO encoding might look like this:\n",
    "\n",
    "| Token | Tag       |\n",
    "|-------|-----------|\n",
    "| John  | B-Person  |\n",
    "| Smith | I-Person  |\n",
    "| works | O         |\n",
    "| at    | O         |\n",
    "| Google| B-Organization |\n",
    "| in    | O         |\n",
    "| New   | B-Location|\n",
    "| York  | I-Location|\n",
    "| .     | O         |\n",
    "\n",
    "Here, the words \"John\" and \"Smith\" form a person entity, \"Google\" is an organization, and \"New York\" represents a location. Each token is tagged with its corresponding label using the BIO scheme, indicating the boundaries of the named entities in the text.\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "- The BIO scheme allows for granular labeling of tokens within named entities, helping NER models to learn entity boundaries.\n",
    "- It ensures that each token in a sequence is assigned a label indicating whether it is part of an entity, the beginning of an entity, or outside any entity.\n",
    "- The BIO encoding scheme is commonly used in training data preparation for NER tasks, enabling the development of models that can recognize and extract named entities from text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622bf953",
   "metadata": {},
   "source": [
    "# Exploring the dataset\n",
    "In this tutorial, ner dataset provided by Kaggle. It consists of four columns:\n",
    "\n",
    "- sentence number\n",
    "- word\n",
    "- part of speech tag of the word,\n",
    "- NER tag associated with each word.\n",
    "\n",
    "Essential info about the tagged entities in the given dataset:\n",
    "\n",
    "- geo = Geographical Entity\n",
    "- org = Organization\n",
    "- per = Person\n",
    "- gpe = Geopolitical Entity\n",
    "- tim = Time indicator\n",
    "- art = Artifact\n",
    "- eve = Event\n",
    "- nat = Natural Phenomenon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c969b33d",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "We will have to preprocess the dataset, in such a way that every sentence is one row and later tokenise and encode each sentence input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "31b0a1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1  Sentence: 1             of   IN   O\n",
       "2  Sentence: 1  demonstrators  NNS   O\n",
       "3  Sentence: 1           have  VBP   O\n",
       "4  Sentence: 1        marched  VBN   O"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.fillna(method='ffill')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4771865e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['Tag'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d4632205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Tag\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d684c9",
   "metadata": {},
   "source": [
    "We have to create a list of sentences and list of NER Tags associated with each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f81a229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agg_func = lambda s: [(building_name, building_number, \n",
    "#                       city,recipent,street_name,zip_code,state,country) \n",
    "#                      for building_name, building_number, city, recipent,\n",
    "#                      street_name,zip_code,state,country in zip(s[\"building_name\"].values .tolist(),\n",
    "#                                                       s['building_number'].values.tolist(),\n",
    "#                                                       s['city'].values.tolist(),\n",
    "#                                                       s['recipent'].values.tolist(),\n",
    "#                                                       s['street_name'].values.tolist(),\n",
    "#                                                       s['state'].values.tolist(),\n",
    "#                                                       s['country'].values.tolist(),\n",
    "#                                                       s[\"zip_code\"].values.tolist())]\n",
    "#                                                       \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8f48e92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func = lambda s:[(w,p,t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                               s[\"POS\"].values.tolist(),\n",
    "                                               s[\"Tag\"].values.tolist())] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ebd3945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.groupby(['Sentence #']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "38dc3193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[\"Sentence #\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "51e3cc9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Sentence_POS_Tag_Pair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>[(Thousands, NNS, O), (of, IN, O), (demonstrat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 10</td>\n",
       "      <td>[(Iranian, JJ, B-gpe), (officials, NNS, O), (s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 100</td>\n",
       "      <td>[(Helicopter, NN, O), (gunships, NNS, O), (Sat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>[(They, PRP, O), (left, VBD, O), (after, IN, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 10000</td>\n",
       "      <td>[(U.N., NNP, B-geo), (relief, NN, O), (coordin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentence #                              Sentence_POS_Tag_Pair\n",
       "0      Sentence: 1  [(Thousands, NNS, O), (of, IN, O), (demonstrat...\n",
       "1     Sentence: 10  [(Iranian, JJ, B-gpe), (officials, NNS, O), (s...\n",
       "2    Sentence: 100  [(Helicopter, NN, O), (gunships, NNS, O), (Sat...\n",
       "3   Sentence: 1000  [(They, PRP, O), (left, VBD, O), (after, IN, O...\n",
       "4  Sentence: 10000  [(U.N., NNP, B-geo), (relief, NN, O), (coordin..."
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_func=data.groupby(['Sentence #']).apply(agg_func).reset_index().rename(columns={0:'Sentence_POS_Tag_Pair'})\n",
    "agg_func.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "65c7a78c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Address'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m agg_data\u001b[38;5;241m=\u001b[39m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAddress\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mapply(agg_func)\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m0\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSentence_POS_Tag_Pair\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m      2\u001b[0m agg_data\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:8402\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[0;32m   8399\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   8400\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[1;32m-> 8402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   8403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8405\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8408\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8410\u001b[0m \u001b[43m    \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8413\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:965\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgrouper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_grouper\n\u001b[1;32m--> 965\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmutated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m obj\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py:888\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[0;32m    886\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 888\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    890\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m    891\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Address'"
     ]
    }
   ],
   "source": [
    "agg_data=data.groupby(['Address']).apply(agg_func).reset_index().rename(columns={0:'Sentence_POS_Tag_Pair'})\n",
    "agg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae048446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
